# Plan: 1-2 - Create Verification Report Template

## Objective
Design and create the VERIFICATION_REPORT.md template that structures verification results, including the new FR4.1 Feature Completeness section.

## Context
The verification report is the primary output of reis_verifier. It must clearly communicate pass/fail status, test results, success criteria validation, **feature completeness status (FR4.1)**, code quality, and actionable recommendations.

**FR4.1 Enhancement:** Report must include a dedicated Feature Completeness section showing task-by-task completion status with evidence for completed tasks and missing deliverables for incomplete tasks.

**Key Requirements:**
- Clear executive summary (pass/fail at a glance)
- Test results with details
- **Feature Completeness section (NEW - FR4.1)** - Critical addition
- Success criteria validation
- Code quality metrics
- Documentation status
- Actionable recommendations
- Next steps

## Dependencies
- Wave 1.1 (Subagent specification must define report requirements)

## Tasks

<task type="auto">
<name>Create VERIFICATION_REPORT.md template with FR4.1 section</name>
<files>templates/VERIFICATION_REPORT.md</files>
<action>
Create a comprehensive verification report template that reis_verifier will populate.

**Template Structure:**

```markdown
# Verification Report: {Phase/Plan Name}

**Date:** {ISO timestamp}  
**Verified By:** reis_verifier  
**Status:** {✅ PASSED | ❌ FAILED | ⚠️ PASSED WITH WARNINGS}

---

## Executive Summary

{One-paragraph summary of verification results}

**Overall Status:** {PASS/FAIL}  
**Tests:** {X/Y passed}  
**Feature Completeness:** {X/Y tasks complete (Z%)}  
**Success Criteria:** {X/Y met}  
**Code Quality:** {PASS/WARNINGS/FAIL}  
**Critical Issues:** {Count}

---

## Feature Completeness (FR4.1)

**Status:** {✅ COMPLETE (100%) | ❌ INCOMPLETE (X%)}  
**Tasks Completed:** {X}/{Y} ({Z%})

### Task-by-Task Analysis

#### ✅ Task 1: {Task Name}
**Status:** Complete  
**Evidence:**
- File: `{file_path}` exists ({line_count} lines)
- Function: `{function_name}()` found at line {line_number}
- Test: `{test_file}` exists
- Endpoint: `{method} {path}` defined in routes
- Documentation: Mentioned in {doc_file}

#### ❌ Task 2: {Task Name}
**Status:** INCOMPLETE - FEATURE MISSING  
**Missing Deliverables:**
- File: `{expected_file}` NOT FOUND
- Function: `{expected_function}()` NOT FOUND (grep returned 0 matches)
- Test: `{expected_test_file}` NOT FOUND
- Endpoint: `{method} {path}` NOT FOUND in routes

**Search Evidence:**
```bash
$ git ls-files | grep "{pattern}"
# No matches

$ grep -r "{function_name}" src/
# No matches
```

**Impact:** {HIGH | MEDIUM | LOW} - {Impact description}  
**Recommendation:** {Specific action needed}

#### ✅ Task 3: {Task Name}
**Status:** Complete  
**Evidence:**
- {Evidence items}

---

## Test Results

**Status:** {✅ All tests pass | ❌ {X} tests failing | ⚠️ No tests found}  
**Framework:** {Jest | Vitest | Node Test | npm test}

**Metrics:**
- Total: {total}
- Passed: {passed} ✅
- Failed: {failed} ❌
- Pending: {pending} ⏸️
- Duration: {duration}ms
- Coverage: {coverage}% (if available)

### Failed Tests
{If any tests failed, list them here with error details}

```
Test: {test_name}
File: {test_file}:{line}
Error: {error_message}
```

---

## Success Criteria Validation

**Status:** {✅ All criteria met | ❌ {X} criteria unmet}  
**Criteria Met:** {X}/{Y}

### Individual Criteria

#### ✅ Criterion 1: {criterion_text}
**Status:** Met  
**Evidence:** {How this was verified}

#### ❌ Criterion 2: {criterion_text}
**Status:** Unmet  
**Evidence:** {Why this failed}  
**Action Needed:** {What to fix}

---

## Code Quality

**Status:** {✅ PASS | ⚠️ WARNINGS | ❌ FAIL}

### Syntax Validation
- {✅ | ❌} No syntax errors

### Linting (if available)
- {✅ | ❌} Lint checks passed
- Warnings: {count}
- Errors: {count}

### Common Issues
- {List any detected issues}

---

## Documentation

**Status:** {✅ COMPLETE | ⚠️ INCOMPLETE | ❌ MISSING}

### Required Documentation
- {✅ | ❌} README.md exists and up-to-date
- {✅ | ❌} CHANGELOG.md updated
- {✅ | ❌} API documentation (if applicable)
- {✅ | ❌} Code comments adequate

### Issues Found
- {List documentation issues}

---

## Issues Summary

### Critical Issues ({count})
1. {Issue description with impact}

### Major Issues ({count})
1. {Issue description}

### Minor Issues ({count})
1. {Issue description}

---

## Recommendations

{Based on verification results, provide actionable recommendations}

**Immediate Actions Required:**
1. {Action 1}
2. {Action 2}

**Before Proceeding to Next Phase:**
- {Requirement 1}
- {Requirement 2}

**Optional Improvements:**
- {Suggestion 1}
- {Suggestion 2}

---

## Next Steps

{✅ PASSED} → Ready to proceed to {next_phase}  
{❌ FAILED} → Fix issues above and re-verify

**Re-verification Command:**
```bash
reis verify {phase_or_plan}
```

---

**Verification Complete**  
*Report generated by reis_verifier v{version}*
```

**Key Features:**
1. **Executive Summary** - Quick pass/fail determination
2. **Feature Completeness Section (FR4.1)** - CRITICAL NEW SECTION
   - Task-by-task breakdown
   - Evidence for completed tasks
   - Missing deliverables for incomplete tasks
   - Impact assessment
   - Completion percentage
3. **Test Results** - Detailed test metrics
4. **Success Criteria** - Individual criterion validation
5. **Code Quality** - Syntax and linting results
6. **Documentation** - Doc completeness check
7. **Recommendations** - Actionable next steps

**Template Variables** (to be replaced by verifier):
- `{Phase/Plan Name}` - From PLAN.md
- `{ISO timestamp}` - Current datetime
- `{X/Y tasks complete}` - FR4.1 completion rate
- `{Task Name}` - From PLAN.md tasks
- `{Evidence items}` - From verification checks
- `{test_name}`, `{test_file}` - From test output
- `{criterion_text}` - From PLAN.md success criteria

**Critical: FR4.1 Section Format**
The Feature Completeness section MUST:
- List ALL tasks from PLAN.md
- Show ✅ or ❌ for each task
- Provide evidence for completed tasks (file paths, line numbers, function names)
- List missing deliverables for incomplete tasks
- Include search evidence (show grep/git ls-files output)
- Calculate and display completion percentage
- Assess impact (HIGH/MEDIUM/LOW)
- Provide specific recommendations

Save to: `templates/VERIFICATION_REPORT.md`
</action>
<verify>
```bash
# Check template exists
test -f templates/VERIFICATION_REPORT.md && echo "✅ Template created"

# Verify key sections exist
grep -q "## Executive Summary" templates/VERIFICATION_REPORT.md && echo "✅ Executive Summary section"
grep -q "## Feature Completeness" templates/VERIFICATION_REPORT.md && echo "✅ Feature Completeness section (FR4.1)"
grep -q "## Test Results" templates/VERIFICATION_REPORT.md && echo "✅ Test Results section"
grep -q "## Success Criteria" templates/VERIFICATION_REPORT.md && echo "✅ Success Criteria section"
grep -q "## Recommendations" templates/VERIFICATION_REPORT.md && echo "✅ Recommendations section"

# Verify FR4.1 specific elements
grep -q "Task-by-Task Analysis" templates/VERIFICATION_REPORT.md && echo "✅ Task analysis section"
grep -q "Missing Deliverables" templates/VERIFICATION_REPORT.md && echo "✅ Missing deliverables tracking"
grep -q "Tasks Completed.*%" templates/VERIFICATION_REPORT.md && echo "✅ Completion percentage"

# Check template variables are present
grep -q "{Task Name}\|{evidence}\|{X/Y}" templates/VERIFICATION_REPORT.md && echo "✅ Template variables present"

wc -l templates/VERIFICATION_REPORT.md
```
</verify>
<done>
- templates/VERIFICATION_REPORT.md created with complete structure
- Executive Summary section for quick status
- Feature Completeness section (FR4.1) with task-by-task breakdown
- Task completion percentage calculation
- Evidence and missing deliverables sections
- Test Results, Success Criteria, Code Quality, Documentation sections
- Recommendations and Next Steps sections
- All template variables defined
- Format supports both passing and failing scenarios
</done>
</task>

<task type="auto">
<name>Create STATE.md verification entry template</name>
<files>templates/STATE_VERIFICATION_ENTRY.md</files>
<action>
Create a template for verification entries that will be added to STATE.md.

**Template Content:**

```markdown
### Verification: {Phase/Plan Name}
**Date:** {ISO timestamp}  
**Status:** {PASSED | FAILED | PASSED_WITH_WARNINGS}  
**Verifier:** reis_verifier v{version}

**Results:**
- Tests: {X/Y passed}
- Feature Completeness: {X/Y tasks ({Z%})}
- Success Criteria: {X/Y met}
- Code Quality: {PASS | WARNINGS | FAIL}

**Issues:** {count} critical, {count} major, {count} minor

**Report:** `.planning/verification/{phase_name}/VERIFICATION_REPORT.md`

{If FAILED:}
**Action Required:** Fix issues and re-verify before proceeding

{If PASSED:}
**Next Phase:** Ready for {next_phase}
```

**Integration Notes:**
This template will be used by reis_verifier to add entries to STATE.md under a "Verification History" section. Each verification attempt creates a new entry.

**Example Usage in STATE.md:**

```markdown
## Verification History

### Verification: Phase 2 - Core Implementation
**Date:** 2024-01-15T14:30:00Z  
**Status:** FAILED  
**Verifier:** reis_verifier v1.0

**Results:**
- Tests: 15/18 passed
- Feature Completeness: 2/3 tasks (66%)
- Success Criteria: 4/6 met
- Code Quality: WARNINGS

**Issues:** 1 critical, 2 major, 3 minor

**Report:** `.planning/verification/phase-2-core-implementation/VERIFICATION_REPORT.md`

**Action Required:** Fix issues and re-verify before proceeding

---

### Verification: Phase 2 - Core Implementation (Re-verification)
**Date:** 2024-01-15T16:45:00Z  
**Status:** PASSED  
**Verifier:** reis_verifier v1.0

**Results:**
- Tests: 18/18 passed
- Feature Completeness: 3/3 tasks (100%)
- Success Criteria: 6/6 met
- Code Quality: PASS

**Issues:** 0 critical, 0 major, 1 minor

**Report:** `.planning/verification/phase-2-core-implementation/VERIFICATION_REPORT_2.md`

**Next Phase:** Ready for Phase 3
```

Save to: `templates/STATE_VERIFICATION_ENTRY.md`
</action>
<verify>
```bash
# Check template exists
test -f templates/STATE_VERIFICATION_ENTRY.md && echo "✅ STATE template created"

# Verify key fields
grep -q "Date:\|Status:\|Verifier:" templates/STATE_VERIFICATION_ENTRY.md && echo "✅ Metadata fields present"
grep -q "Feature Completeness" templates/STATE_VERIFICATION_ENTRY.md && echo "✅ FR4.1 completeness field"
grep -q "Tests:\|Success Criteria:\|Code Quality:" templates/STATE_VERIFICATION_ENTRY.md && echo "✅ Results fields present"

wc -l templates/STATE_VERIFICATION_ENTRY.md
```
</verify>
<done>
- templates/STATE_VERIFICATION_ENTRY.md created
- Includes verification metadata (date, status, verifier version)
- Shows results summary (tests, feature completeness, criteria, quality)
- Tracks issues by severity
- Links to full report
- Provides next steps based on status
- Example usage documented
</done>
</task>

<task type="auto">
<name>Document report design and usage</name>
<files>.planning/verifier-project/phases/1-design-and-specification/REPORT_DESIGN.md</files>
<action>
Create documentation explaining the report design, FR4.1 integration, and how the templates will be used.

**Content:**

```markdown
# Verification Report Design

## Overview
This document explains the structure and usage of verification reports, including the critical FR4.1 Feature Completeness validation.

## Report Structure

### 1. Executive Summary
**Purpose:** Quick pass/fail determination  
**Audience:** Developers, CI/CD systems  
**Key Metrics:** Overall status, completion %, critical issues

### 2. Feature Completeness (FR4.1) - CRITICAL
**Purpose:** Detect missing/incomplete tasks  
**Method:** Parse PLAN.md, verify all deliverables exist  
**Output:** Task-by-task status with evidence

**Why This Matters:**
Executors may skip tasks without errors. This section catches incomplete implementations before they cause downstream issues.

**Detection:**
- File existence checks
- Code pattern matching (grep for functions/classes)
- Git diff analysis
- Test presence verification
- Documentation mentions

**Report Format:**
```
✅ Task 1: Complete (evidence: files, functions, tests found)
❌ Task 2: INCOMPLETE (missing: X.js, functionY(), test Z)
✅ Task 3: Complete
Result: 66% complete → FAIL
```

### 3. Test Results
**Purpose:** Validate functionality  
**Method:** Run npm test, parse output  
**Output:** Pass/fail counts, failed test details

### 4. Success Criteria Validation
**Purpose:** Verify PLAN.md acceptance criteria  
**Method:** Check each criterion individually  
**Output:** Per-criterion pass/fail with evidence

### 5. Code Quality
**Purpose:** Catch syntax errors, linting issues  
**Method:** node --check, eslint if configured  
**Output:** Quality score, issue list

### 6. Documentation
**Purpose:** Ensure docs are complete  
**Method:** Check required files, consistency  
**Output:** Doc completeness status

### 7. Recommendations
**Purpose:** Provide actionable next steps  
**Method:** Analyze all results, prioritize issues  
**Output:** Immediate actions, requirements, improvements

## FR4.1 Implementation Details

### Task Parsing
```javascript
// Extract tasks from PLAN.md
const tasks = parsePlanTasks(planContent);
// tasks = [
//   { name: 'Task 1', files: ['a.js', 'b.js'], ... },
//   { name: 'Task 2', files: ['c.js'], ... }
// ]
```

### Deliverable Extraction
```javascript
// From task, extract expected deliverables
const deliverables = extractDeliverables(task);
// deliverables = [
//   { type: 'file', path: 'src/auth/login.js' },
//   { type: 'function', name: 'authenticateUser' },
//   { type: 'test', path: 'test/auth/login.test.js' }
// ]
```

### Verification
```javascript
// Check each deliverable
for (const deliverable of deliverables) {
  const exists = await verifyDeliverable(deliverable);
  if (!exists) {
    task.status = 'INCOMPLETE';
    task.missing.push(deliverable);
  }
}
```

### Completion Calculation
```javascript
const completedTasks = tasks.filter(t => t.status === 'COMPLETE').length;
const completionRate = (completedTasks / tasks.length) * 100;
const overallStatus = completionRate === 100 ? 'PASS' : 'FAIL';
```

## Template Usage

### During Verification
1. Load `templates/VERIFICATION_REPORT.md`
2. Replace template variables with actual values
3. Populate each section with verification results
4. Calculate FR4.1 completion percentage
5. Generate recommendations based on issues found
6. Save to `.planning/verification/{phase}/VERIFICATION_REPORT.md`

### STATE.md Integration
1. Load `templates/STATE_VERIFICATION_ENTRY.md`
2. Replace variables with verification summary
3. Append to STATE.md under "Verification History"
4. Preserve existing STATE.md content
5. Update phase status if verification passed

## Example Workflow

```bash
# Run verification
reis verify phase-2

# Verifier:
# 1. Load PLAN.md
# 2. Run tests → 17/18 passed
# 3. Check feature completeness → 2/3 tasks (66%)
# 4. Validate criteria → 5/6 met
# 5. Check quality → WARNINGS
# 6. Generate report → FAILED
# 7. Update STATE.md

# Output:
❌ Verification FAILED
- Task 2 incomplete (missing password-reset.js)
- 1 test failing
- See: .planning/verification/phase-2/VERIFICATION_REPORT.md

# Developer fixes issues, re-verifies
reis verify phase-2

# Output:
✅ Verification PASSED
- All 3 tasks complete (100%)
- All tests passing (18/18)
- Ready for Phase 3
```

## Critical Success Factors

### FR4.1 Must:
- ✅ Parse ALL tasks from PLAN.md
- ✅ Verify ALL deliverables exist
- ✅ Report missing items with evidence
- ✅ Calculate accurate completion %
- ✅ FAIL if any task incomplete (<100%)

### Report Must:
- ✅ Be clear and actionable
- ✅ Provide evidence for all claims
- ✅ Prioritize issues by severity
- ✅ Give specific recommendations
- ✅ Enable quick re-verification

## Anti-Patterns

❌ Don't report pass if any task incomplete  
❌ Don't skip FR4.1 checks (critical)  
❌ Don't generate vague recommendations  
❌ Don't corrupt STATE.md on updates  
✅ DO fail fast on missing features  
✅ DO provide clear evidence  
✅ DO make reports actionable  
```

Save to: `.planning/verifier-project/phases/1-design-and-specification/REPORT_DESIGN.md`
</action>
<verify>
```bash
# Check documentation exists
test -f .planning/verifier-project/phases/1-design-and-specification/REPORT_DESIGN.md && echo "✅ Design doc created"

# Verify FR4.1 documentation
grep -q "FR4.1\|Feature Completeness" .planning/verifier-project/phases/1-design-and-specification/REPORT_DESIGN.md && echo "✅ FR4.1 documented"
grep -q "Task Parsing\|Deliverable Extraction" .planning/verifier-project/phases/1-design-and-specification/REPORT_DESIGN.md && echo "✅ Implementation details"

wc -l .planning/verifier-project/phases/1-design-and-specification/REPORT_DESIGN.md
```
</verify>
<done>
- REPORT_DESIGN.md created with comprehensive documentation
- Explains report structure and purpose of each section
- FR4.1 Feature Completeness implementation detailed
- Task parsing, deliverable extraction, completion calculation explained
- Template usage documented
- Example workflow included
- Critical success factors and anti-patterns listed
</done>
</task>

## Success Criteria
- ✅ templates/VERIFICATION_REPORT.md created with all required sections
- ✅ **Feature Completeness section (FR4.1) prominently included**
- ✅ Task-by-task analysis format defined
- ✅ Evidence and missing deliverables sections specified
- ✅ Completion percentage calculation documented
- ✅ templates/STATE_VERIFICATION_ENTRY.md created
- ✅ STATE.md entry format includes FR4.1 metrics
- ✅ REPORT_DESIGN.md documents template usage and FR4.1 implementation
- ✅ All template variables clearly marked
- ✅ Examples demonstrate both passing and failing scenarios

## Verification

```bash
# Verify templates exist
ls -lh templates/VERIFICATION_REPORT.md templates/STATE_VERIFICATION_ENTRY.md

# Check FR4.1 integration in report template
grep -n "Feature Completeness\|Task-by-Task" templates/VERIFICATION_REPORT.md | head -5

# Check STATE template
cat templates/STATE_VERIFICATION_ENTRY.md

# Verify design documentation
cat .planning/verifier-project/phases/1-design-and-specification/REPORT_DESIGN.md | head -50
```

---

*This plan will be executed by reis_executor in a fresh context.*
